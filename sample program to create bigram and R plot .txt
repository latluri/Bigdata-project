library(tm)
library(wordcloud)
library(NLP)
library(SnowballC)
library(stringi)
library(NLP)
library(tm)
library(SnowballC)
library(RWeka)
library(ggplot2)
library(grid)
library(wordcloud)
library(RColorBrewer)
library(parallel)
library(xtable)
library(qdap)
B <- read.delim("~/Final_B", header=FALSE)
C <- read.delim("~/Final_C", header=FALSE)
D <- read.delim("~/Final_D", header=FALSE)
save.image("C:/Users/Pavan/Desktop/wellsfargo/fargo/.RData")
Bank_tweeter <- read.csv("C:/Users/Pavan/Desktop/wellsfargo/cleaned_backup/Bank_tweeter.txt", header=FALSE)
View(Bank_tweeter)
tweets <- VCorpus(DirSource("C:/Users/Pavan/Documents/Files/"))
tweets <- VCorpus(DirSource("C:/Users/Pavan/Documents/Files/"))
rm(tweets)
tweets <- VCorpus(DirSource("C:/Users/Pavan/Documents/Files/"))
tweets<- tm_map(tweets, removeWords, “INTERNET”)
tweets<- tm_map(tweets, removeWords,'INTERNET'')

save.image("C:/Users/Pavan/Desktop/wellsfargo/fargo/.RData")

tweets<- tm_map(tweets, removeWords,'INTERNET')
tweets<- tm_map(tweets, removeWords,'Name')
tweets<-tm_map(tweets,content_transformer(stripWhitespace))
tweets<-tm_map(tweets,content_transformer(tolower()))
tweets<-tm_map(tweets,content_transformer(tolower)
tweets<-tm_map(tweets,content_transformer(tolower))
inspect(tweets)
tweets<-tm_map(tweets,removeWords,stopwords('English'))
tweets<-tm_map(tweets,content_transformer(stemDocument))
(f <- content_transformer(function(x, pattern) gsub(pattern, "", x)))
tm_map(crude, f, "[[:digit:]]+")[[1]]
tweets<-tm_map(tweets,content_transformer(stemCompletion))
tweets<-tm_map(tweets,content_transformer(stemCompletion))
tweets<-tm_map(tweets,DICTIONARY,content_transformer(stemCompletion))
tweets<-tm_map(tweets,FUN = DICTIONARY,content_transformer(stemCompletion))
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
TdmBi_A_A  <- TermDocumentMatrix(tweets, control = list(tokenize = BigramTokenizer))
TdmBi_A_A_RS <-  removeSparseTerms(TdmBi_A_A, 0.1)
freq.bi_A_A  <- rowSums(as.matrix(TdmBi_A_A_RS))
freq.bi_A_A_S  <- sort(freq.bi_A_A, decreasing = TRUE)
df.freq.bi_A_A_S  <- data.frame("Term"=names(head(freq.bi_A_A_S,100)), "Frequency"=head(freq.bi_A_A_S,100))
df.freq.bi_A_A_S$Term1 <- reorder(df.freq.bi_A_A_S$Term, df.freq.bi_A_A_S$Frequency)
p2_A_A <-
ggplot(df.freq.bi_A_A_S, aes(x = Term1, y = Frequency)) +
geom_bar(stat = "identity", color="gray55", fill="steelblue2") +
geom_text(data=df.freq.bi_A_A_S,aes(x=Term1,y=-250,label=Frequency),vjust=0, size=3) +
xlab("Terms") + ylab("Count") + ggtitle("Top 100 BiGram Tokenized Word Frequency") +
theme(plot.title = element_text(lineheight=.8, face="bold")) +
coord_flip()

plot(p2_A_A)
wordcloud(words = df.freq.bi_A_A_S$Term1,freq = df.freq.bi_A_A_S$Frequency,random.order=FALSE,rot.per=0.35,use.r.layout=FALSE,colors=brewer.pal(8, "Dark2"))text(x=0.5, y=1.1, "BiGram Word Cloud")
